---
title: "Homework2"
author: "Brian Schetzsle"
date: "2/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("R/Homework2.R", local = knitr::knit_global())
library(mvtnorm)
library(kableExtra)
library(microbenchmark)
```

# Question 7

I first generate a random mean vector and positive definite Sigma matrix (using a function I found online).

```{r}
Posdef <- function (n, ev = runif(n, 0, 10)) 
{
  Z <- matrix(ncol=n, rnorm(n^2))
  decomp <- qr(Z)
  Q <- qr.Q(decomp) 
  R <- qr.R(decomp)
  d <- diag(R)
  ph <- d / abs(d)
  O <- Q %*% diag(ph)
  Z <- t(O) %*% diag(ev) %*% O
  return(Z)
}

N = 1000
n = 4

mu = runif(n,-5,5)
dim(mu) = c(n,1)

Sigma = Posdef(n=n)

X = cholesky_mvn(N, mu, Sigma)
```

Below are the true mean $\mu$ and the sample mean, which are close:

```{r}
t(mu)
apply(X, 2, mean)
```

Below are the true covariance matrix $\Sigma$ and the sample covariance matrix, which are also close: 

```{r}
Sigma
var(X)
```

# Question 8

## QR Decomposition

```{r}
data = read.csv("homework2_regression.csv")
X = as.matrix(data[,2:6])
Y = as.matrix(data[,1])

QR_result = QR_regression(Y, X)
```

```{r echo=FALSE}
colnames(QR_result) = c("QR Regression Coefficients")
rownames(QR_result) = c("Beta_0","Beta_1","Beta_2","Beta_3","Beta_4")
kbl(QR_result)
```

```{r}
SVD_result = SVD_regression(Y, X)
```

```{r echo=FALSE}
colnames(SVD_result) = c("QR Regression Coefficients")
rownames(SVD_result) = c("Beta_0","Beta_1","Beta_2","Beta_3","Beta_4")
kbl(SVD_result)
```

```{r}
result = microbenchmark(QR_regression(Y, X), SVD_regression(Y, X))

boxplot(result, main="Benchmark Result", names=c("QR", "SVD"), xlab="Method", ylab="Milliseconds")

```

The regression using SVD decomposition is faster than QR decomposition, which is in accordance with the order of complexity discussed in class.

\qquad
\qquad



Github repository is located here:

https://github.com/bschetzsle/STATS230

